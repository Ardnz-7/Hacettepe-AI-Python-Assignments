{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "#reading and editing data\n",
    "df = pd.read_csv(\"16P.csv\", encoding=\"cp1252\")\n",
    "df = df.drop(columns = \"Response Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning personality types to numbers\n",
    "convert = {\"ESTJ\": 0,\n",
    "\"ENTJ\": 1,\n",
    "\"ESFJ\": 2,\n",
    "\"ENFJ\": 3,\n",
    "\"ISTJ\": 4,\n",
    "\"ISFJ\": 5,\n",
    "\"INTJ\": 6,\n",
    "\"INFJ\": 7,\n",
    "\"ESTP\": 8,\n",
    "\"ESFP\": 9,\n",
    "\"ENTP\": 10,\n",
    "\"ENFP\": 11,\n",
    "\"ISTP\": 12,\n",
    "\"ISFP\": 13,\n",
    "\"INTP\": 14,\n",
    "\"INFP\": 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding personality types to numbers\n",
    "df[\"Personality\"]= df[\"Personality\"].map(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59999, 60)\n"
     ]
    }
   ],
   "source": [
    "n_df = df.drop(columns = \"Personality\")\n",
    "n_df = n_df.to_numpy()\n",
    "print(n_df.shape)\n",
    "df = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "\n",
    "n_df = (n_df - n_df.min()) / (n_df.max() - n_df.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting data\n",
    "train_data = df[:int(len(df) * 0.8)]\n",
    "test_data = df[int(len(df) * 0.8):]\n",
    "\n",
    "X_train = train_data[:, :-1]\n",
    "y_train = train_data[:, -1]\n",
    "X_test = test_data[:, :-1]\n",
    "y_test = test_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting data\n",
    "train_data_n = n_df[:int(len(n_df) * 0.8)]\n",
    "test_data_n = n_df[int(len(n_df) * 0.8):]\n",
    "\n",
    "X_train_n = train_data_n[:, :-1]\n",
    "y_train_n = train_data_n[:, -1]\n",
    "X_test_n = test_data_n[:, :-1]\n",
    "y_test_n = test_data_n[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "def knn_predict(X_train, y_train, X_test, k):\n",
    "    # calculate the distance\n",
    "    distances = -2 * np.dot(X_test, X_train.T) + np.sum(X_train**2, axis=1) + np.sum(X_test**2, axis=1)[:, np.newaxis]\n",
    "    # find k nearest neighbours\n",
    "    nearest_indices = np.argsort(distances, axis=1)[:, :k]\n",
    "    # take neighbours labels\n",
    "    nearest_labels = y_train[nearest_indices]\n",
    "    nearest_labels = np.array(nearest_labels, dtype=int)\n",
    "    # take the mod of the labels\n",
    "    predictions = np.apply_along_axis(lambda x: np.argmax(np.bincount(x)), axis=1, arr=nearest_labels)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find accuracys\n",
    "def accuracy(y_pred, y_true):\n",
    "    return np.mean(y_pred == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find precisions\n",
    "def precision(y_pred, y_true):\n",
    "    tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    return tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find recalls\n",
    "def recall(y_pred, y_true):\n",
    "    tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    return tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.97775\n",
      "Precision:  0.9986033519553073\n",
      "Recall:  1.0\n",
      "Accuracy:  0.9885\n",
      "Precision:  0.9986168741355463\n",
      "Recall:  1.0\n",
      "Accuracy:  0.9888333333333333\n",
      "Precision:  0.9986168741355463\n",
      "Recall:  1.0\n",
      "Accuracy:  0.98875\n",
      "Precision:  0.9986168741355463\n",
      "Recall:  1.0\n",
      "Accuracy:  0.989\n",
      "Precision:  0.9986168741355463\n",
      "Recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "# for the actual data\n",
    "k = [1,3,5,7,9]\n",
    "for i in k:\n",
    "    y_pred = knn_predict(X_train, y_train, X_test, i)\n",
    "\n",
    "    acc = accuracy(y_pred, y_test)\n",
    "    prec = precision(y_pred, y_test)\n",
    "    rec = recall(y_pred, y_test)\n",
    "\n",
    "    print(\"Accuracy: \", acc)\n",
    "    print(\"Precision: \", prec)\n",
    "    print(\"Recall: \", rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.05316666666666667\n",
      "Precision:  1.0\n",
      "Recall:  0.17533432392273401\n",
      "Accuracy:  0.048666666666666664\n",
      "Precision:  1.0\n",
      "Recall:  0.0950965824665676\n",
      "Accuracy:  0.04608333333333333\n",
      "Precision:  1.0\n",
      "Recall:  0.04903417533432392\n",
      "Accuracy:  0.04475\n",
      "Precision:  1.0\n",
      "Recall:  0.02526002971768202\n",
      "Accuracy:  0.04441666666666667\n",
      "Precision:  1.0\n",
      "Recall:  0.019316493313521546\n"
     ]
    }
   ],
   "source": [
    "#for the normalized data\n",
    "for i in k:\n",
    "    y_pred = knn_predict(X_train_n, y_train_n, X_test_n, i)\n",
    "\n",
    "    acc = accuracy(y_pred, y_test_n)\n",
    "    prec = precision(y_pred, y_test_n)\n",
    "    rec = recall(y_pred, y_test_n)\n",
    "\n",
    "    print(\"Accuracy: \", acc)\n",
    "    print(\"Precision: \", prec)\n",
    "    print(\"Recall: \", rec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3c6fa48223653632e36e1c1c55d0784c10d20b3e63ac8964e727525f01de2fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
